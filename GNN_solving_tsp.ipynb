{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from itertools import permutations\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from tqdm import tqdm  # For progress bars\n",
    "\n",
    "def create_data_model(num_selected_cities=8, seed=None):\n",
    "    \"\"\"\n",
    "    Stores the data for the TSP problem with a variable number of cities.\n",
    "\n",
    "    Parameters:\n",
    "    - num_selected_cities (int): Number of cities to include in the TSP instance (including depot).\n",
    "    - seed (int, optional): Seed for random city selection to ensure reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - data (dict): A dictionary containing TSP data, including selected cities, their coordinates,\n",
    "                  and the corresponding distance matrix.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    # Coordinates of the cities (latitude, longitude)\n",
    "    data[\"cities_info\"] = {\n",
    "        \"New York\": (40.7128, -74.0060),\n",
    "        \"Los Angeles\": (34.0522, -118.2437),\n",
    "        \"Chicago\": (41.8781, -87.6298),\n",
    "        \"Denver\": (39.7392, -104.9903),\n",
    "        \"Dallas\": (32.7767, -96.7970),\n",
    "        \"Seattle\": (47.6062, -122.3321),\n",
    "        \"Boston\": (42.3601, -71.0589),\n",
    "        \"San Francisco\": (37.7749, -122.4194),\n",
    "        \"St. Louis\": (38.6270, -90.1994),\n",
    "        \"Houston\": (29.7604, -95.3698),\n",
    "        \"Phoenix\": (33.4484, -112.0740),\n",
    "        \"Salt Lake City\": (40.7608, -111.8910),\n",
    "    }\n",
    "    # List of all cities in the order corresponding to the distance matrix\n",
    "    all_cities = [\n",
    "        \"New York\",\n",
    "        \"Los Angeles\",\n",
    "        \"Chicago\",\n",
    "        \"Denver\",\n",
    "        \"Dallas\",\n",
    "        \"Seattle\",\n",
    "        \"Boston\",\n",
    "        \"San Francisco\",\n",
    "        \"St. Louis\",\n",
    "        \"Houston\",\n",
    "        \"Phoenix\",\n",
    "        \"Salt Lake City\",\n",
    "    ]\n",
    "    data[\"all_cities\"] = all_cities  # Keep the original list for reference\n",
    "\n",
    "    # Distance matrix in miles (12x12 matrix)\n",
    "    full_distance_matrix = [\n",
    "        # NY    LA    Chicago Denver Dallas Seattle Boston San Francisco St. Louis Houston Phoenix Salt Lake\n",
    "        [0,    2451, 713,    1631, 1374, 2408, 213,    2571, 875,    1420, 2145, 1972],  # New York\n",
    "        [2451, 0,    1745,   831, 1240, 959,  2596, 403,   1589, 1374, 357, 579],      # Los Angeles\n",
    "        [713,  1745, 0,      920, 803, 1737, 851,  1858, 262,    940, 1453, 1260],      # Chicago\n",
    "        [1631, 831,  920,    0,   663, 1021, 1769, 949,   796,    879, 586, 371],       # Denver\n",
    "        [1374, 1240, 803,    663, 0,   1681, 1551, 1765, 547,    225, 887, 999],       # Dallas\n",
    "        [2408, 959,  1737,  1021, 1681, 0,    2493, 678,   1724, 1891, 1114, 701],      # Seattle\n",
    "        [213,  2596, 851,    1769, 1551, 2493, 0,    2699, 1038, 1605, 2300, 2099],    # Boston\n",
    "        [2571, 403,  1858,   949, 1765, 678,  2699, 0,    1744, 1645, 653, 600],       # San Francisco\n",
    "        [875,  1589, 262,    796, 547, 1724, 1038, 1744, 0,      679, 1272, 1162],      # St. Louis\n",
    "        [1420, 1374, 940,    879, 225, 1891, 1605, 1645, 679,    0,    1017, 1200],     # Houston\n",
    "        [2145, 357,  1453,   586, 887, 1114, 2300, 653,   1272, 1017, 0, 504],        # Phoenix\n",
    "        [1972, 579,  1260,   371, 999, 701,  2099, 600,   1162, 1200, 504, 0],        # Salt Lake City\n",
    "    ]\n",
    "\n",
    "    # Validate num_selected_cities\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    if num_selected_cities < 2:\n",
    "        raise ValueError(\"At least two cities must be selected (including the depot).\")\n",
    "    if num_selected_cities > len(all_cities):\n",
    "        raise ValueError(f\"Cannot select {num_selected_cities} cities from {len(all_cities)} available.\")\n",
    "\n",
    "    # Define the depot (always included)\n",
    "    depot = \"New York\"\n",
    "    selected_cities = [depot]\n",
    "    remaining_cities = [city for city in all_cities if city != depot]\n",
    "\n",
    "    if num_selected_cities > 1:\n",
    "        selected_additional_cities = random.sample(remaining_cities, num_selected_cities - 1)\n",
    "        selected_cities.extend(selected_additional_cities)\n",
    "\n",
    "    # Get indices of selected cities based on the original all_cities list\n",
    "    selected_indices = [all_cities.index(city) for city in selected_cities]\n",
    "\n",
    "    # Extract the subset distance matrix\n",
    "    subset_distance_matrix = []\n",
    "    for i in selected_indices:\n",
    "        row = [full_distance_matrix[i][j] for j in selected_indices]\n",
    "        subset_distance_matrix.append(row)\n",
    "\n",
    "    # Update data dictionary with selected cities and subset distance matrix\n",
    "    data[\"cities\"] = selected_cities\n",
    "    data[\"distance_matrix\"] = subset_distance_matrix\n",
    "    data[\"num_cities\"] = len(selected_cities)\n",
    "    data[\"depot\"] = 0  # Depot is always the first city in the selected_cities list\n",
    "\n",
    "    # Create node features for selected cities\n",
    "    node_features = []\n",
    "    for city in selected_cities:\n",
    "        lat, lon = data[\"cities_info\"][city]\n",
    "        node_features.append([lat, lon])\n",
    "    data[\"node_features\"] = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "    # Create edge index for the selected cities (fully connected graph)\n",
    "    edge_index = []\n",
    "    for i in range(data[\"num_cities\"]):\n",
    "        for j in range(data[\"num_cities\"]):\n",
    "            if i != j:\n",
    "                edge_index.append([i, j])\n",
    "    data[\"edge_index\"] = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Create PyTorch Geometric Data object\n",
    "    data[\"pyg_data\"] = Data(x=data[\"node_features\"], edge_index=data[\"edge_index\"])\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_tsp_brute_force(data):\n",
    "    \"\"\"\n",
    "    Solves the TSP problem using brute force for a single instance.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): TSP data model.\n",
    "\n",
    "    Returns:\n",
    "    - optimal_route (list): List of city indices representing the optimal tour.\n",
    "    - min_distance (float): Total distance of the optimal tour.\n",
    "    \"\"\"\n",
    "    cities = data[\"cities\"]\n",
    "    distance_matrix = data[\"distance_matrix\"]\n",
    "    depot = data[\"depot\"]\n",
    "    num_cities = data[\"num_cities\"]\n",
    "\n",
    "    # Generate all possible routes starting and ending at the depot\n",
    "    city_indices = list(range(num_cities))\n",
    "    city_indices.remove(depot)  # Fix the depot at the start\n",
    "\n",
    "    min_distance = float('inf')\n",
    "    optimal_route = None\n",
    "\n",
    "    for perm in permutations(city_indices):\n",
    "        # Construct the full route starting and ending at the depot\n",
    "        route = [depot] + list(perm) + [depot]\n",
    "        # Calculate the total distance\n",
    "        total_distance = 0\n",
    "        for i in range(len(route) - 1):\n",
    "            from_city = route[i]\n",
    "            to_city = route[i + 1]\n",
    "            total_distance += distance_matrix[from_city][to_city]\n",
    "        # Update optimal route if necessary\n",
    "        if total_distance < min_distance:\n",
    "            min_distance = total_distance\n",
    "            optimal_route = route\n",
    "\n",
    "    return optimal_route, min_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSPDataset(Dataset):\n",
    "    def __init__(self, data_list, tours):\n",
    "        \"\"\"\n",
    "        data_list: List of PyTorch Geometric Data objects representing TSP instances.\n",
    "        tours: List of lists, where each sublist is the sequence of city indices representing the tour.\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.tours = tours\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx], self.tours[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tsp_dataset(num_instances=100, min_cities=5, max_cities=8, seed=None):\n",
    "    \"\"\"\n",
    "    Generates a dataset of TSP instances with optimal tours.\n",
    "\n",
    "    Parameters:\n",
    "    - num_instances (int): Number of TSP instances to generate.\n",
    "    - min_cities (int): Minimum number of cities in an instance.\n",
    "    - max_cities (int): Maximum number of cities in an instance.\n",
    "    - seed (int, optional): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - data_list (list): List of PyTorch Geometric Data objects.\n",
    "    - tours (list): List of optimal tours corresponding to each instance.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    data_list = []\n",
    "    tours = []\n",
    "\n",
    "    for i in tqdm(range(num_instances), desc=\"Generating TSP Instances\"):\n",
    "        num_selected_cities = random.randint(min_cities, max_cities)\n",
    "        data = create_data_model(num_selected_cities=num_selected_cities, seed=None)\n",
    "        optimal_route, min_distance = solve_tsp_brute_force(data)\n",
    "        data_list.append(data[\"pyg_data\"])\n",
    "        tours.append(optimal_route)\n",
    "\n",
    "    return data_list, tours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GATConv\n",
    "\n",
    "class GATEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4):\n",
    "        super(GATEncoder, self).__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=0.6)\n",
    "        self.gat2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=0.6)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x  # Final node embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Device configuration: use CUDA if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self, encoder, hidden_size, output_size):\n",
    "        super(PointerNetwork, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Decoder RNN\n",
    "        self.decoder_rnn = nn.LSTMCell(hidden_size, hidden_size)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.pointer = nn.Linear(hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, data, target=None):\n",
    "        # Encode the graph\n",
    "        encoder_outputs = self.encoder(data.x, data.edge_index)  # [num_nodes, hidden_size]\n",
    "\n",
    "        # Initialize decoder state\n",
    "        batch_size = 1  # Assuming single instance\n",
    "        decoder_hidden = torch.zeros(batch_size, self.hidden_size)\n",
    "        decoder_cell = torch.zeros(batch_size, self.hidden_size)\n",
    "\n",
    "        # Start with the depot\n",
    "        input = encoder_outputs[data.depot].unsqueeze(0)  # [batch_size, hidden_size]\n",
    "\n",
    "        # Store the tour\n",
    "        tour = []\n",
    "        pointers = []\n",
    "\n",
    "        # Mask to keep track of visited cities\n",
    "        mask = torch.zeros(data.num_nodes, dtype=torch.bool)\n",
    "        mask[data.depot] = True  # Start at depot\n",
    "\n",
    "        for _ in range(data.num_cities - 1):  # Exclude depot at the end\n",
    "            # Decode step\n",
    "            decoder_hidden, decoder_cell = self.decoder_rnn(input, (decoder_hidden, decoder_cell))\n",
    "\n",
    "            # Calculate attention scores\n",
    "            attn_scores = self.pointer(torch.cat([decoder_hidden, encoder_outputs], dim=1))  # [num_nodes, 1]\n",
    "            attn_scores = attn_scores.squeeze(-1)  # [num_nodes]\n",
    "            attn_scores = attn_scores.masked_fill(mask, float('-inf'))  # Mask visited cities\n",
    "            attn_weights = F.softmax(attn_scores, dim=0)  # [num_nodes]\n",
    "\n",
    "            # Pointer to next city\n",
    "            pointer = torch.argmax(attn_weights).item()\n",
    "            tour.append(pointer)\n",
    "            pointers.append(attn_weights)\n",
    "\n",
    "            # Update mask\n",
    "            mask[pointer] = True\n",
    "\n",
    "            # Prepare input for next step\n",
    "            input = encoder_outputs[pointer].unsqueeze(0)\n",
    "\n",
    "        # Append depot to complete the tour\n",
    "        tour.append(data.depot)\n",
    "\n",
    "        return tour, pointers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TSPModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(TSPModel, self).__init__()\n",
    "        self.encoder = GATEncoder(in_channels, hidden_channels, out_channels)\n",
    "        self.pointer_network = PointerNetwork(self.encoder, hidden_size=out_channels, output_size=out_channels)\n",
    "\n",
    "    def forward(self, data, target=None):\n",
    "        tour, pointers = self.pointer_network(data, target)\n",
    "        return tour, pointers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(tour_pred, tour_true):\n",
    "    \"\"\"\n",
    "    Calculates the cross-entropy loss for the predicted tour.\n",
    "\n",
    "    Parameters:\n",
    "    - tour_pred (list): List of predicted city indices.\n",
    "    - tour_true (list): List of true city indices.\n",
    "\n",
    "    Returns:\n",
    "    - loss (float): Calculated loss value.\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    for pred, true in zip(tour_pred[:-1], tour_true[:-1]):  # Exclude the final depot\n",
    "        pred_tensor = torch.tensor(pred).unsqueeze(0)  # [1]\n",
    "        true_tensor = torch.tensor([true])\n",
    "        loss += F.cross_entropy(pred_tensor, true_tensor)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train_model(model, dataloader, epochs=50, learning_rate=1e-3, device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains the TSP model.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): The TSP model to train.\n",
    "    - dataloader (DataLoader): DataLoader for the training dataset.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - learning_rate (float): Learning rate for the optimizer.\n",
    "    - device (str): Device to run the training on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - model (nn.Module): The trained model.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch}/{epochs}\"):\n",
    "            data, tour = batch\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            tour_pred, _ = model(data)\n",
    "            loss = loss_function(tour_pred, tour)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tsp_dataset(num_instances=100, min_cities=5, max_cities=8, seed=None):\n",
    "    \"\"\"\n",
    "    Generates a dataset of TSP instances with optimal tours.\n",
    "\n",
    "    Parameters:\n",
    "    - num_instances (int): Number of TSP instances to generate.\n",
    "    - min_cities (int): Minimum number of cities in an instance.\n",
    "    - max_cities (int): Maximum number of cities in an instance.\n",
    "    - seed (int, optional): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - data_list (list): List of PyTorch Geometric Data objects.\n",
    "    - tours (list): List of optimal tours corresponding to each instance.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "\n",
    "    data_list = []\n",
    "    tours = []\n",
    "\n",
    "    for _ in tqdm(range(num_instances), desc=\"Generating TSP Instances\"):\n",
    "        num_selected_cities = random.randint(min_cities, max_cities)\n",
    "        data = create_data_model(num_selected_cities=num_selected_cities, seed=None)\n",
    "        optimal_route, min_distance = solve_tsp_brute_force(data)\n",
    "        data_list.append(data[\"pyg_data\"])\n",
    "        tours.append(optimal_route)\n",
    "\n",
    "    return data_list, tours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, data, tour_true, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a single TSP instance.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): The trained TSP model.\n",
    "    - data (Data): PyTorch Geometric Data object representing the TSP instance.\n",
    "    - tour_true (list): The true optimal tour (list of city indices).\n",
    "    - device (str): Device to run the evaluation on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "    - total_distance_pred (float): Total distance of the predicted tour.\n",
    "    - total_distance_true (float): Total distance of the true tour.\n",
    "    - accuracy (float): Percentage of cities correctly predicted at each step.\n",
    "    - tour_pred (list): The predicted tour (list of city indices).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        tour_pred, _ = model(data)\n",
    "\n",
    "    # Calculate total distance for predicted tour\n",
    "    distance_matrix = data[\"distance_matrix\"]\n",
    "    total_distance_pred = calculate_total_distance(tour_pred, distance_matrix)\n",
    "\n",
    "    # Calculate total distance for true tour\n",
    "    total_distance_true = calculate_total_distance(tour_true, distance_matrix)\n",
    "\n",
    "    # Calculate accuracy (cities correctly predicted at each step)\n",
    "    correct_steps = sum([pred == true for pred, true in zip(tour_pred, tour_true)])\n",
    "    accuracy = correct_steps / len(tour_true) * 100\n",
    "\n",
    "    return total_distance_pred, total_distance_true, accuracy, tour_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_route(route, cities_info, filename=\"predicted_route.png\"):\n",
    "    \"\"\"\n",
    "    Plots the given route on a map.\n",
    "\n",
    "    Parameters:\n",
    "    - route (list): List of city names representing the tour.\n",
    "    - cities_info (dict): Dictionary with city names as keys and (lat, lon) tuples as values.\n",
    "    - filename (str): Filename to save the plot.\n",
    "    \"\"\"\n",
    "    # Extract latitude and longitude for the route\n",
    "    lats = []\n",
    "    lons = []\n",
    "    for city in route:\n",
    "        lat, lon = cities_info[city]\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "\n",
    "    # Create a plot with Cartopy\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    ax = plt.axes(projection=ccrs.LambertConformal())\n",
    "    ax.set_extent([-125, -66.5, 24, 50], ccrs.Geodetic())\n",
    "\n",
    "    # Add map features\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.STATES, linestyle=':')\n",
    "\n",
    "    # Plot the cities\n",
    "    ax.scatter(lons, lats, color='red', s=100, transform=ccrs.Geodetic())\n",
    "\n",
    "    # Annotate city names\n",
    "    for city, lat, lon in zip(route, lats, lons):\n",
    "        ax.text(lon + 0.5, lat + 0.5, city, fontsize=9, transform=ccrs.Geodetic())\n",
    "\n",
    "    # Plot the route lines\n",
    "    ax.plot(lons, lats, color='blue', linewidth=2, marker='o', transform=ccrs.Geodetic())\n",
    "\n",
    "    # Add title\n",
    "    plt.title(\"Predicted TSP Route\", fontsize=16)\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from itertools import permutations\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# =======================\n",
    "# Data Model Function\n",
    "# =======================\n",
    "\n",
    "def create_data_model(num_selected_cities=12, seed=None):\n",
    "    \"\"\"\n",
    "    Stores the data for the TSP problem with a variable number of cities.\n",
    "\n",
    "    Parameters:\n",
    "    - num_selected_cities (int): Number of cities to include in the TSP instance (including depot).\n",
    "    - seed (int, optional): Seed for random city selection to ensure reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - data (dict): A dictionary containing TSP data, including selected cities, their coordinates,\n",
    "                  and the corresponding distance matrix.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    # Coordinates of the cities (latitude, longitude)\n",
    "    data[\"cities_info\"] = {\n",
    "        \"New York\": (40.7128, -74.0060),\n",
    "        \"Los Angeles\": (34.0522, -118.2437),\n",
    "        \"Chicago\": (41.8781, -87.6298),\n",
    "        \"Denver\": (39.7392, -104.9903),\n",
    "        \"Dallas\": (32.7767, -96.7970),\n",
    "        \"Seattle\": (47.6062, -122.3321),\n",
    "        \"Boston\": (42.3601, -71.0589),\n",
    "        \"San Francisco\": (37.7749, -122.4194),\n",
    "        \"St. Louis\": (38.6270, -90.1994),\n",
    "        \"Houston\": (29.7604, -95.3698),\n",
    "        \"Phoenix\": (33.4484, -112.0740),\n",
    "        \"Salt Lake City\": (40.7608, -111.8910),\n",
    "    }\n",
    "    # List of all cities in the order corresponding to the distance matrix\n",
    "    all_cities = [\n",
    "        \"New York\",\n",
    "        \"Los Angeles\",\n",
    "        \"Chicago\",\n",
    "        \"Denver\",\n",
    "        \"Dallas\",\n",
    "        \"Seattle\",\n",
    "        \"Boston\",\n",
    "        \"San Francisco\",\n",
    "        \"St. Louis\",\n",
    "        \"Houston\",\n",
    "        \"Phoenix\",\n",
    "        \"Salt Lake City\",\n",
    "    ]\n",
    "    data[\"all_cities\"] = all_cities  # Keep the original list for reference\n",
    "\n",
    "    # Distance matrix in miles (12x12 matrix)\n",
    "    full_distance_matrix = [\n",
    "        # NY    LA    Chicago Denver Dallas Seattle Boston San Francisco St. Louis Houston Phoenix Salt Lake\n",
    "        [0,    2451, 713,    1631, 1374, 2408, 213,    2571, 875,    1420, 2145, 1972],  # New York\n",
    "        [2451, 0,    1745,   831, 1240, 959,  2596, 403,   1589, 1374, 357, 579],      # Los Angeles\n",
    "        [713,  1745, 0,      920, 803, 1737, 851,  1858, 262,    940, 1453, 1260],      # Chicago\n",
    "        [1631, 831,  920,    0,   663, 1021, 1769, 949,   796,    879, 586, 371],       # Denver\n",
    "        [1374, 1240, 803,    663, 0,   1681, 1551, 1765, 547,    225, 887, 999],       # Dallas\n",
    "        [2408, 959,  1737,  1021, 1681, 0,    2493, 678,   1724, 1891, 1114, 701],      # Seattle\n",
    "        [213,  2596, 851,    1769, 1551, 2493, 0,    2699, 1038, 1605, 2300, 2099],    # Boston\n",
    "        [2571, 403,  1858,   949, 1765, 678,  2699, 0,    1744, 1645, 653, 600],       # San Francisco\n",
    "        [875,  1589, 262,    796, 547, 1724, 1038, 1744, 0,      679, 1272, 1162],      # St. Louis\n",
    "        [1420, 1374, 940,    879, 225, 1891, 1605, 1645, 679,    0,    1017, 1200],     # Houston\n",
    "        [2145, 357,  1453,   586, 887, 1114, 2300, 653,   1272, 1017, 0, 504],        # Phoenix\n",
    "        [1972, 579,  1260,   371, 999, 701,  2099, 600,   1162, 1200, 504, 0],        # Salt Lake City\n",
    "    ]\n",
    "\n",
    "    # Validate num_selected_cities\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    if num_selected_cities < 2:\n",
    "        raise ValueError(\"At least two cities must be selected (including the depot).\")\n",
    "    if num_selected_cities > len(all_cities):\n",
    "        raise ValueError(f\"Cannot select {num_selected_cities} cities from {len(all_cities)} available.\")\n",
    "\n",
    "    # Define the depot (always included)\n",
    "    depot = \"New York\"\n",
    "    selected_cities = [depot]\n",
    "    remaining_cities = [city for city in all_cities if city != depot]\n",
    "\n",
    "    if num_selected_cities > 1:\n",
    "        selected_additional_cities = random.sample(remaining_cities, num_selected_cities - 1)\n",
    "        selected_cities.extend(selected_additional_cities)\n",
    "\n",
    "    # Get indices of selected cities based on the original all_cities list\n",
    "    selected_indices = [all_cities.index(city) for city in selected_cities]\n",
    "\n",
    "    # Extract the subset distance matrix\n",
    "    subset_distance_matrix = []\n",
    "    for i in selected_indices:\n",
    "        row = [full_distance_matrix[i][j] for j in selected_indices]\n",
    "        subset_distance_matrix.append(row)\n",
    "\n",
    "    # Update data dictionary with selected cities and subset distance matrix\n",
    "    data[\"cities\"] = selected_cities\n",
    "    data[\"distance_matrix\"] = subset_distance_matrix\n",
    "    data[\"num_cities\"] = len(selected_cities)\n",
    "    data[\"depot\"] = 0  # Depot is always the first city in the selected_cities list\n",
    "\n",
    "    # Create node features for selected cities\n",
    "    node_features = []\n",
    "    for city in selected_cities:\n",
    "        lat, lon = data[\"cities_info\"][city]\n",
    "        node_features.append([lat, lon])\n",
    "    data[\"node_features\"] = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "    # Create edge index for the selected cities (fully connected graph)\n",
    "    edge_index = []\n",
    "    for i in range(data[\"num_cities\"]):\n",
    "        for j in range(data[\"num_cities\"]):\n",
    "            if i != j:\n",
    "                edge_index.append([i, j])\n",
    "    data[\"edge_index\"] = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Create PyTorch Geometric Data object\n",
    "    data[\"pyg_data\"] = Data(x=data[\"node_features\"], edge_index=data[\"edge_index\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "# =======================\n",
    "# Calculate Total Distance\n",
    "# =======================\n",
    "\n",
    "def calculate_total_distance(route, distance_matrix):\n",
    "    \"\"\"\n",
    "    Calculates the total distance of the given route.\n",
    "\n",
    "    Parameters:\n",
    "    - route (list): List of city indices representing the tour.\n",
    "    - distance_matrix (list of lists): Distance matrix in miles.\n",
    "\n",
    "    Returns:\n",
    "    - total_distance (float): Total distance of the tour.\n",
    "    \"\"\"\n",
    "    total_distance = 0\n",
    "    for i in range(len(route) - 1):\n",
    "        from_city = route[i]\n",
    "        to_city = route[i + 1]\n",
    "        total_distance += distance_matrix[from_city][to_city]\n",
    "    return total_distance\n",
    "\n",
    "# =======================\n",
    "# Plot Route Function\n",
    "# =======================\n",
    "\n",
    "def plot_route(route, cities_info, temp_dir, frame_number):\n",
    "    \"\"\"\n",
    "    Plots the route and saves the plot as an image in the temporary directory.\n",
    "\n",
    "    Parameters:\n",
    "    - route (list): List of city names representing the tour.\n",
    "    - cities_info (dict): Dictionary with city names as keys and (lat, lon) tuples as values.\n",
    "    - temp_dir (str): Path to the directory where frames are saved.\n",
    "    - frame_number (int): Frame number for naming the saved image.\n",
    "    \"\"\"\n",
    "    # Extract latitude and longitude for the route\n",
    "    lats = []\n",
    "    lons = []\n",
    "    for city in route:\n",
    "        lat, lon = cities_info[city]\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "\n",
    "    # Create a plot with Cartopy\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    ax = plt.axes(projection=ccrs.LambertConformal())\n",
    "    ax.set_extent([-125, -66.5, 24, 50], ccrs.Geodetic())\n",
    "\n",
    "    # Add map features\n",
    "    ax.add_feature(cfeature.LAND)\n",
    "    ax.add_feature(cfeature.OCEAN)\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "    ax.add_feature(cfeature.STATES, linestyle=':')\n",
    "\n",
    "    # Plot the cities\n",
    "    ax.scatter(lons, lats, color='red', s=100, transform=ccrs.Geodetic())\n",
    "\n",
    "    # Annotate city names\n",
    "    for city, lat, lon in zip(route, lats, lons):\n",
    "        ax.text(lon + 0.5, lat + 0.5, city, fontsize=9, transform=ccrs.Geodetic())\n",
    "\n",
    "    # Plot the route lines\n",
    "    ax.plot(lons, lats, color='blue', linewidth=2, marker='o', transform=ccrs.Geodetic())\n",
    "\n",
    "    # Add frame number as subtitle\n",
    "    plt.title(\"Selected TSP Route\", fontsize=16)\n",
    "    plt.suptitle(f\"Frame {frame_number}\", fontsize=10, y=0.95)\n",
    "\n",
    "    # Save the figure\n",
    "    frame_filename = os.path.join(temp_dir, f\"frame_{frame_number:05d}.png\")\n",
    "    plt.savefig(frame_filename)\n",
    "    plt.close()\n",
    "\n",
    "# =======================\n",
    "# Create GIF Function\n",
    "# =======================\n",
    "\n",
    "def create_gif_from_frames(route_history, temp_dir, gif_filename=\"tsp_route.gif\", duration=0.5):\n",
    "    \"\"\"\n",
    "    Creates a GIF from the saved plot frames based on the route history.\n",
    "\n",
    "    Parameters:\n",
    "    - route_history (list): List of routes (each route is a list of city names).\n",
    "    - temp_dir (str): Directory where the plot images are stored.\n",
    "    - gif_filename (str): Filename for the output GIF.\n",
    "    - duration (float): Duration between frames in the GIF in seconds.\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    print(\"Creating GIF...\")\n",
    "\n",
    "    for idx, route in enumerate(route_history):\n",
    "        frame_filename = os.path.join(temp_dir, f\"frame_{idx + 1:05d}.png\")\n",
    "        if os.path.exists(frame_filename):\n",
    "            images.append(imageio.imread(frame_filename))\n",
    "        else:\n",
    "            print(f\"Warning: {frame_filename} does not exist and will be skipped.\")\n",
    "\n",
    "    if images:\n",
    "        imageio.mimsave(gif_filename, images, duration=duration)\n",
    "        print(f\"GIF saved as {gif_filename}\")\n",
    "    else:\n",
    "        print(\"No images found to create GIF.\")\n",
    "\n",
    "# =======================\n",
    "# Solve TSP Brute Force\n",
    "# =======================\n",
    "\n",
    "def solve_tsp_brute_force_with_history(data, temp_dir):\n",
    "    \"\"\"\n",
    "    Solves the TSP problem using brute force and records route history.\n",
    "\n",
    "    Parameters:\n",
    "    - data (dict): TSP data model.\n",
    "    - temp_dir (str): Path to the directory where frames are saved.\n",
    "\n",
    "    Returns:\n",
    "    - optimal_route (list): List of city indices representing the optimal tour.\n",
    "    - min_distance (float): Total distance of the optimal tour.\n",
    "    - permutations_checked (int): Number of permutations evaluated.\n",
    "    - elapsed_time (float): Time taken to solve the TSP.\n",
    "    - route_history (list): List of optimal routes found during the search.\n",
    "    \"\"\"\n",
    "    cities = data[\"cities\"]\n",
    "    distance_matrix = data[\"distance_matrix\"]\n",
    "    depot = data[\"depot\"]\n",
    "    num_cities = data[\"num_cities\"]\n",
    "\n",
    "    # Generate all possible routes starting and ending at the depot\n",
    "    city_indices = list(range(num_cities))\n",
    "    city_indices.remove(depot)  # Fix the depot at the start\n",
    "\n",
    "    min_distance = float('inf')\n",
    "    optimal_route = None\n",
    "    route_history = []  # To store each new optimal route\n",
    "\n",
    "    # Calculate total permutations: (n-1)!\n",
    "    total_permutations = 1\n",
    "    for i in range(2, num_cities):\n",
    "        total_permutations *= i\n",
    "\n",
    "    print(f\"Total permutations to evaluate: {total_permutations}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    permutations_checked = 0\n",
    "\n",
    "    for perm in permutations(city_indices):\n",
    "        # Construct the full route starting and ending at the depot\n",
    "        route = [depot] + list(perm) + [depot]\n",
    "        # Calculate the total distance\n",
    "        total_distance = 0\n",
    "        valid = True\n",
    "        for i in range(len(route) - 1):\n",
    "            from_city = route[i]\n",
    "            to_city = route[i + 1]\n",
    "            distance = distance_matrix[from_city][to_city]\n",
    "            total_distance += distance\n",
    "            # Branch and Bound: if current distance exceeds min_distance, stop evaluating this permutation\n",
    "            if total_distance >= min_distance:\n",
    "                valid = False\n",
    "                break\n",
    "        if valid and total_distance < min_distance:\n",
    "            min_distance = total_distance\n",
    "            optimal_route = route\n",
    "            # Convert route indices to city names\n",
    "            route_cities = [data[\"cities\"][city] for city in optimal_route]\n",
    "            # Save the new optimal route to history\n",
    "            route_history.append(list(route_cities))\n",
    "            # Save the plot frame\n",
    "            plot_route(list(route_cities), data[\"cities_info\"], temp_dir, len(route_history))\n",
    "            # Print progress\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"New optimal distance: {min_distance} miles found at permutation {permutations_checked}\")\n",
    "            print(f\"Route: {' -> '.join(route_cities)}\")\n",
    "        permutations_checked += 1\n",
    "        # Progress indicator every 1,000,000 permutations\n",
    "        if permutations_checked % 1000000 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Checked {permutations_checked} permutations in {elapsed:.2f} seconds...\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    if optimal_route:\n",
    "        return optimal_route, min_distance, permutations_checked, elapsed_time, route_history\n",
    "    else:\n",
    "        return None, None, permutations_checked, elapsed_time, route_history\n",
    "\n",
    "# =======================\n",
    "# GNN/GAT Model Definitions\n",
    "# =======================\n",
    "\n",
    "class GATEncoder(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads=4):\n",
    "        super(GATEncoder, self).__init__()\n",
    "        self.gat1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=0.6)\n",
    "        self.gat2 = GATConv(hidden_channels * heads, out_channels, heads=1, concat=False, dropout=0.6)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return x  # Final node embeddings\n",
    "\n",
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self, encoder, hidden_size, output_size):\n",
    "        super(PointerNetwork, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        # Decoder RNN\n",
    "        self.decoder_rnn = nn.LSTMCell(hidden_size, hidden_size)\n",
    "\n",
    "        # Attention mechanism\n",
    "        self.pointer = nn.Linear(hidden_size * 2, 1)\n",
    "\n",
    "    def forward(self, data, target=None):\n",
    "        # Encode the graph\n",
    "        encoder_outputs = self.encoder(data.x, data.edge_index)  # [num_nodes, hidden_size]\n",
    "\n",
    "        # Initialize decoder state\n",
    "        batch_size = 1  # Assuming single instance\n",
    "        decoder_hidden = torch.zeros(batch_size, self.hidden_size).to(encoder_outputs.device)\n",
    "        decoder_cell = torch.zeros(batch_size, self.hidden_size).to(encoder_outputs.device)\n",
    "\n",
    "        # Start with the depot\n",
    "        input = encoder_outputs[data.depot].unsqueeze(0)  # [batch_size, hidden_size]\n",
    "\n",
    "        # Store the tour\n",
    "        tour = []\n",
    "        pointers = []\n",
    "\n",
    "        # Mask to keep track of visited cities\n",
    "        mask = torch.zeros(data.num_nodes, dtype=torch.bool).to(encoder_outputs.device)\n",
    "        mask[data.depot] = True  # Start at depot\n",
    "\n",
    "        for _ in range(data.num_cities - 1):\n",
    "            # Decode step\n",
    "            decoder_hidden, decoder_cell = self.decoder_rnn(input, (decoder_hidden, decoder_cell))\n",
    "\n",
    "            # Calculate attention scores\n",
    "            attn_scores = self.pointer(torch.cat([decoder_hidden, encoder_outputs], dim=1))  # [num_nodes, 1]\n",
    "            attn_scores = attn_scores.squeeze(-1)  # [num_nodes]\n",
    "            attn_scores = attn_scores.masked_fill(mask, float('-inf'))  # Mask visited cities\n",
    "            attn_weights = F.softmax(attn_scores, dim=0)  # [num_nodes]\n",
    "\n",
    "            # Pointer to next city\n",
    "            pointer = torch.argmax(attn_weights).item()\n",
    "            tour.append(pointer)\n",
    "            pointers.append(attn_weights)\n",
    "\n",
    "            # Update mask\n",
    "            mask[pointer] = True\n",
    "\n",
    "            # Prepare input for next step\n",
    "            input = encoder_outputs[pointer].unsqueeze(0)\n",
    "\n",
    "        # Complete the tour by returning to depot\n",
    "        tour.append(data.depot)\n",
    "        return tour, pointers\n",
    "\n",
    "class TSPModel(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(TSPModel, self).__init__()\n",
    "        self.encoder = GATEncoder(in_channels, hidden_channels, out_channels)\n",
    "        self.pointer_network = PointerNetwork(self.encoder, hidden_size=out_channels, output_size=out_channels)\n",
    "\n",
    "    def forward(self, data, target=None):\n",
    "        tour, pointers = self.pointer_network(data, target)\n",
    "        return tour, pointers\n",
    "\n",
    "# =======================\n",
    "# Dataset Class\n",
    "# =======================\n",
    "\n",
    "class TSPDataset(Dataset):\n",
    "    def __init__(self, data_list, tours):\n",
    "        \"\"\"\n",
    "        data_list: List of PyTorch Geometric Data objects representing TSP instances.\n",
    "        tours: List of lists, where each sublist is the sequence of city indices representing the optimal tour.\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.tours = tours\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data_list[idx], self.tours[idx]\n",
    "\n",
    "# =======================\n",
    "# Generate TSP Dataset\n",
    "# =======================\n",
    "\n",
    "def generate_tsp_dataset(num_samples, num_cities, seed=None):\n",
    "    \"\"\"\n",
    "    Generates a dataset of TSP instances and their optimal tours using brute-force.\n",
    "\n",
    "    Parameters:\n",
    "    - num_samples (int): Number of TSP instances to generate.\n",
    "    - num_cities (int): Number of cities per TSP instance (including depot).\n",
    "    - seed (int, optional): Seed for random selection to ensure reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - data_list (list): List of PyTorch Geometric Data objects representing TSP instances.\n",
    "    - tours (list): List of lists, where each sublist is the sequence of city indices representing the optimal tour.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    data_list = []\n",
    "    tours = []\n",
    "\n",
    "    for sample_idx in range(num_samples):\n",
    "        # Create a random data model\n",
    "        data = create_data_model(num_selected_cities=num_cities, seed=seed)\n",
    "\n",
    "        cities = data[\"cities\"]\n",
    "        distance_matrix = data[\"distance_matrix\"]\n",
    "        depot = data[\"depot\"]\n",
    "        num_cities = data[\"num_cities\"]\n",
    "\n",
    "        # Generate all possible routes starting and ending at the depot\n",
    "        city_indices = list(range(num_cities))\n",
    "        city_indices.remove(depot)  # Fix the depot at the start\n",
    "\n",
    "        min_distance = float('inf')\n",
    "        optimal_route = None\n",
    "\n",
    "        # For practical purposes, limit to small n (e.g., n <= 10)\n",
    "        if num_cities > 10:\n",
    "            raise ValueError(\"Brute-force TSP solver is impractical for more than 10 cities.\")\n",
    "\n",
    "        for perm in permutations(city_indices):\n",
    "            # Construct the full route starting and ending at the depot\n",
    "            route = [depot] + list(perm) + [depot]\n",
    "            # Calculate the total distance\n",
    "            total_distance = 0\n",
    "            for i in range(len(route) - 1):\n",
    "                from_city = route[i]\n",
    "                to_city = route[i + 1]\n",
    "                total_distance += distance_matrix[from_city][to_city]\n",
    "            # Update optimal route if necessary\n",
    "            if total_distance < min_distance:\n",
    "                min_distance = total_distance\n",
    "                optimal_route = route\n",
    "\n",
    "        if optimal_route is None:\n",
    "            raise Exception(\"No valid route found.\")\n",
    "\n",
    "        # Append to datasets\n",
    "        data_list.append(data[\"pyg_data\"])\n",
    "        tours.append(optimal_route)\n",
    "\n",
    "        print(f\"Generated sample {sample_idx + 1}/{num_samples}\")\n",
    "\n",
    "    return data_list, tours\n",
    "\n",
    "# =======================\n",
    "# Loss Function\n",
    "# =======================\n",
    "\n",
    "def loss_function(tour_pred, tour_true):\n",
    "    \"\"\"\n",
    "    Calculates the cross-entropy loss between predicted tour and true tour.\n",
    "\n",
    "    Parameters:\n",
    "    - tour_pred (list): List of predicted city indices.\n",
    "    - tour_true (list): List of true city indices.\n",
    "\n",
    "    Returns:\n",
    "    - loss (torch.Tensor): Computed loss value.\n",
    "    \"\"\"\n",
    "    loss = 0.0\n",
    "    for pred, true in zip(tour_pred, tour_true):\n",
    "        pred_tensor = torch.tensor([pred], dtype=torch.long).to(tour_pred[0].device)\n",
    "        true_tensor = torch.tensor([true], dtype=torch.long).to(tour_pred[0].device)\n",
    "        loss += F.cross_entropy(pred_tensor, true_tensor)\n",
    "    return loss\n",
    "\n",
    "# =======================\n",
    "# Train Model Function\n",
    "# =======================\n",
    "\n",
    "def train_model(model, dataloader, epochs=100, learning_rate=1e-3, device='cpu'):\n",
    "    \"\"\"\n",
    "    Trains the GNN/GAT model.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): The GNN/GAT model to train.\n",
    "    - dataloader (DataLoader): DataLoader for the training dataset.\n",
    "    - epochs (int): Number of training epochs.\n",
    "    - learning_rate (float): Learning rate for the optimizer.\n",
    "    - device (torch.device): Device to train on (CPU or CUDA).\n",
    "\n",
    "    Returns:\n",
    "    - model (nn.Module): The trained model.\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_idx, (data, tour) in enumerate(dataloader):\n",
    "            data = data.to(device)\n",
    "            tour = [int(city) for city in tour[0]]  # Assuming batch_size=1\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            tour_pred, _ = model(data)\n",
    "            loss = loss_function(tour_pred, tour)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# =======================\n",
    "# Evaluate Model Function\n",
    "# =======================\n",
    "\n",
    "def evaluate_model(model, data, tour_true, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates the model on a single TSP instance.\n",
    "\n",
    "    Parameters:\n",
    "    - model (nn.Module): The trained GNN/GAT model.\n",
    "    - data (Data): PyTorch Geometric Data object representing the TSP instance.\n",
    "    - tour_true (list): List of true city indices representing the optimal tour.\n",
    "    - device (torch.device): Device to perform evaluation on.\n",
    "\n",
    "    Returns:\n",
    "    - total_distance (float): Total distance of the predicted tour.\n",
    "    - accuracy (float): Percentage of correctly predicted cities in the tour.\n",
    "    - tour_pred (list): List of predicted city indices representing the tour.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        data = data.to(device)\n",
    "        tour_pred, _ = model(data)\n",
    "    # Calculate total distance\n",
    "    total_distance = calculate_total_distance(tour_pred, data[\"distance_matrix\"])\n",
    "    # Calculate accuracy (excluding the depot at the end)\n",
    "    accuracy = sum([pred == true for pred, true in zip(tour_pred[:-1], tour_true[:-1])]) / (len(tour_true) -1)\n",
    "    return total_distance, accuracy * 100, tour_pred\n",
    "\n",
    "# =======================\n",
    "# Main Function\n",
    "# =======================\n",
    "\n",
    "def main():\n",
    "    # Desired number of cities (including depot)\n",
    "    num_selected_cities = 8  # Change this value as needed (e.g., 5, 7, 10, etc.)\n",
    "\n",
    "    # Optional: Set a seed for reproducibility\n",
    "    seed = 42\n",
    "\n",
    "    # Device configuration: use CUDA if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Create the data model with the specified number of cities\n",
    "    data = create_data_model(num_selected_cities=num_selected_cities, seed=seed)\n",
    "\n",
    "    # Print selected cities and their coordinates\n",
    "    print(f\"\\nSelected {data['num_cities']} Cities:\")\n",
    "    for idx, city in enumerate(data[\"cities\"]):\n",
    "        print(f\"{idx}: {city} at {data['cities_info'][city]}\")\n",
    "\n",
    "    # Display the subset distance matrix\n",
    "    print(\"\\nSubset Distance Matrix (in miles):\")\n",
    "    for row in data[\"distance_matrix\"]:\n",
    "        print(row)\n",
    "\n",
    "    # Create a temporary directory to store plot images\n",
    "    temp_dir = \"tsp_temp_frames\"\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\nGenerating TSP Dataset...\")\n",
    "    # Generate dataset (for demonstration, using a single sample)\n",
    "    # For effective training, generate multiple samples\n",
    "    num_samples = 1  # Change as needed\n",
    "    tours = []\n",
    "    data_list, tours = generate_tsp_dataset(num_samples=num_samples, num_cities=num_selected_cities, seed=seed)\n",
    "\n",
    "    # Initialize dataset and dataloader\n",
    "    dataset = TSPDataset(data_list, tours)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = TSPModel(in_channels=2, hidden_channels=128, out_channels=128)\n",
    "\n",
    "    # Train the model\n",
    "    print(\"\\nStarting Training...\")\n",
    "    model = train_model(model, dataloader, epochs=100, learning_rate=1e-3, device=device)\n",
    "\n",
    "    # Evaluate the model on the first sample\n",
    "    print(\"\\nEvaluating the Model on the First Sample...\")\n",
    "    test_data = data_list[0]\n",
    "    test_tour_true = tours[0]\n",
    "    total_distance, accuracy, tour_pred = evaluate_model(model, test_data, test_tour_true, device=device)\n",
    "    print(f\"\\nPredicted Tour: {tour_pred}\")\n",
    "    print(f\"True Tour: {test_tour_true}\")\n",
    "    print(f\"Total Distance: {total_distance} miles\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # Plot the predicted tour\n",
    "    route_cities = [data[\"cities\"][city] for city in tour_pred]\n",
    "    plot_route(route_cities, data[\"cities_info\"], temp_dir=temp_dir, frame_number=1)\n",
    "\n",
    "    # Create the GIF from route history (for demonstration, using the optimal tour)\n",
    "    create_gif_from_frames([route_cities], temp_dir, gif_filename=f\"tsp_route_{num_selected_cities}.gif\", duration=0.5)\n",
    "\n",
    "    print(\"\\nProcess Completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
